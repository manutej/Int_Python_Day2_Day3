{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threads, Processes, and Concurrency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threading\n",
    "\n",
    "- Typically, **concurrency** is created so that we can do some task while I/O is happening (e.g., a server can start processing a new request while waiting for data from a previous request to arrive)\n",
    "\n",
    "- We can create objects that appear to be running independently, but simultaneously\n",
    "\n",
    "- The job of threading is to enable an application to be responsive\n",
    "\n",
    "- CPython, the default implementation of Python, has a Global Interpreter Lock (GIL), which prevents your application from doing two things at once, but rather, the CPU time is being rationed across your threads\n",
    "\n",
    "    What that means: Python does not natively support parallel computing with multiple simultaneous threads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Threading Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 0 started.Thread 1 started.\n",
      "\n",
      "Thread 2 started.\n",
      "Thread 3 started.\n",
      "Thread 4 started.\n",
      "Thread 1 finished.Thread 3 finished.\n",
      "Thread 0 finished.\n",
      "Thread 4 finished.\n",
      "Thread 2 finished.\n",
      "\n",
      "All threads completed.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def worker(thread_id):\n",
    "    print(f\"Thread {thread_id} started.\")\n",
    "    time.sleep(2)  # Simulating some work\n",
    "    print(f\"Thread {thread_id} finished.\")\n",
    "\n",
    "# Create and start multiple threads\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    thread = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"All threads completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `worker` function represents the task that each thread will execute. It takes a `thread_id` as an argument and simulates some work by sleeping for 2 seconds.\n",
    "\n",
    "- We create a list called `threads` to store the thread objects.\n",
    "\n",
    "- Inside the loop, we create a new thread using `threading.Thread`, specifying the target function (`worker`) and its arguments (`i`).\n",
    "\n",
    "- We append each thread to the `threads` list and start it using the `start()` method.\n",
    "\n",
    "- After starting all the threads, we use a loop to wait for each thread to complete using the `join()` method. This ensures that the main thread waits for all the worker threads to finish before proceeding.\n",
    "\n",
    "- Finally, we print a message indicating that all threads have completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated squares up to 15,599,133 * 15,599,133 = 243,332,919,153,424\n",
      "while you typed \"gekk\"\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class InputReader(Thread):\n",
    "    \"\"\"Thread example, extends Thread class\"\"\"\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Whatever is in the run method (or called from\n",
    "        it) is executed in a separate thread\n",
    "        \"\"\"\n",
    "        self.line_of_text = input('Enter some text: ')\n",
    "\n",
    "input('Are you ready? When you hit return the thread will start.')\n",
    "thread = InputReader() # create thread object\n",
    "thread.start() # cf. thread.run() for no concurrency\n",
    "\n",
    "count, result = 1, 1\n",
    "\n",
    "while thread.is_alive():\n",
    "    result = count * count\n",
    "    count += 1\n",
    "\n",
    "print(f'calculated squares up to {count:,} * {count:,} = {result:,}')\n",
    "print(f'while you typed \"{thread.line_of_text}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Think of threads like workers who are extremely efficient at \"multi-tasking\" by being an expert at switching task contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### But...the main problem with threads is also their primary advantage–shared memory\n",
    "\n",
    "- all threads have access to all the memory\n",
    "\n",
    "- what if two threads access the same data?\n",
    "\n",
    "- synchronization is the solution, but it's tricky\n",
    "\n",
    "- bugs due to incorrect synchronization can be very difficult to find due to ordering issues\n",
    "\n",
    "- one solution is to force communication between threads to occur using a data structure that has built in locking, such as `queue.Queue`\n",
    "\n",
    "- disadvantages could be outweighed by the fact that shared memory is FAST, except for the GIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat A Task Every So Often...\n",
    "...using a Timer (subclass of thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiplied up to 0\n",
      "multiplied up to 10000000\n",
      "multiplied up to 20000000\n",
      "multiplied up to 30000000\n",
      "multiplied up to 40000000\n",
      "multiplied up to 50000000\n",
      "multiplied up to 60000000\n",
      "Do the thing you want to every so often\n",
      "multiplied up to 70000000\n",
      "multiplied up to 80000000\n",
      "multiplied up to 90000000\n"
     ]
    }
   ],
   "source": [
    "from threading import Timer, Event\n",
    " \n",
    "def every_so_often():\n",
    "    if not done.is_set():\n",
    "        print('Do the thing you want to every so often')\n",
    "        Timer(5.0, every_so_often).start()\n",
    " \n",
    "done = Event()\n",
    "Timer(5.0, every_so_often).start()\n",
    " \n",
    "for count in range(100_000_000):\n",
    "    prod = count * count\n",
    "    if count % 10_000_000 == 0:\n",
    "        print('multiplied up to', count)\n",
    " \n",
    "done.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Thread Synchronization** and Object Sharing\n",
    "\n",
    "When multiple threads access shared resources concurrently, synchronization mechanisms are necessary to prevent race conditions and ensure data integrity. Let's revisit `BankAccount` class for thread synchronization using locks\n",
    "\n",
    "The `lock` attribute is an instance of threading.Lock, which is used to synchronize access to the shared balance attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deposit: 500, New Balance: 1500\n",
      "Withdrawal: 200, New Balance: 1300\n",
      "Deposit: 500, New Balance: 1800\n",
      "Withdrawal: 200, New Balance: 1600\n",
      "Deposit: 500, New Balance: 2100\n",
      "Withdrawal: 200, New Balance: 1900\n",
      "Deposit: 500, New Balance: 2400\n",
      "Withdrawal: 200, New Balance: 2200\n",
      "Deposit: 500, New Balance: 2700\n",
      "Withdrawal: 200, New Balance: 2500\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "class BankAccount:\n",
    "    def __init__(self, balance):\n",
    "        self.balance = balance\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def deposit(self, amount):\n",
    "        with self.lock:\n",
    "            new_balance = self.balance + amount\n",
    "            self.balance = new_balance\n",
    "            print(f\"Deposit: {amount}, New Balance: {self.balance}\")\n",
    "\n",
    "    def withdraw(self, amount):\n",
    "        with self.lock:\n",
    "            if self.balance >= amount:\n",
    "                new_balance = self.balance - amount\n",
    "                self.balance = new_balance\n",
    "                print(f\"Withdrawal: {amount}, New Balance: {self.balance}\")\n",
    "            else:\n",
    "                print(\"Insufficient funds.\")\n",
    "\n",
    "account = BankAccount(1000)\n",
    "\n",
    "def perform_transactions():\n",
    "    account.deposit(500)\n",
    "    account.withdraw(200)\n",
    "\n",
    "threads = []\n",
    "for _ in range(5):\n",
    "    thread = threading.Thread(target=perform_transactions)\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `deposit` and `withdraw` methods use the `with` statement to acquire the lock before accessing the shared `balance` attribute. This ensures that only one thread can modify the balance at a time, preventing race conditions.\n",
    "\n",
    "- The `perform_transactions` function performs a series of transactions (deposit and withdrawal) on the bank account.\n",
    "\n",
    "- We create multiple threads, each executing the `perform_transactions` function concurrently.\n",
    "\n",
    "- The `join()` method is used to wait for all the threads to complete before the program exits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concurrency: Executing multiple tasks or processes simultaneously, but not necessarily in parallel.\n",
    "\n",
    "“Concurrency is two lines of customers ordering from a single cashier (lines take turns ordering), while Parallelism is two lines of customers ordering from two cashiers (each line with its own cashier)”\n",
    "\n",
    "- Each cashier is a processing unit\n",
    "\n",
    "- Each customer is a task that needs to be taken care of\n",
    "\n",
    "### Parallelism: Executing multiple tasks or processes simultaneously and in parallel, utilizing multiple CPU cores\n",
    "- GIL Lock in Python limits true parallelism in Python, even if you have multiple threads open\n",
    "- Ways around this include relying on multiple processes instead of multiple threads \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing\n",
    "\n",
    "#### Processes are separate instances of a program that run independently and have their own memory space.\n",
    "\n",
    "- the Python `multiprocessing` library is designed for cases where CPU-bound jobs needs to happen in parallel and multiple cores are available\n",
    "advantages\n",
    "\n",
    "- separate memory space for each process\n",
    "\n",
    "- code is usually straightforward compared to threads\n",
    "\n",
    "- **avoids GIL** limitation\n",
    "\n",
    "- eliminates synchronization (assuming no shared memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "work took 0.07891678810119629 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'MuchCPU' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'MuchCPU' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'MuchCPU' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'MuchCPU' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'MuchCPU' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'MuchCPU' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'MuchCPU' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'MuchCPU' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "## RUN FROM COMMAND LINE -> See multiprocess.py\n",
    "# Don't run this in Jupyter, run from command line\n",
    "from multiprocessing import Process, cpu_count\n",
    "import time\n",
    "import os\n",
    "\n",
    "class MuchCPU(Process):\n",
    "    def run(self):\n",
    "        print(os.getpid())\n",
    "        for i in range(200000000):\n",
    "            pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Running...')\n",
    "    procs = [MuchCPU() for f in range(cpu_count())]\n",
    "    t = time.time()\n",
    "    for p in procs:\n",
    "        p.start()\n",
    "    \n",
    "    for p in procs:\n",
    "        p.join()\n",
    "    \n",
    "    print('work took {} seconds'.format(time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing Pools\n",
    "\n",
    "- pools abstract away the overhead of figuring out what code is running in main process and what code is running in subprocess\n",
    "\n",
    "    abstraction restricts the number of places that code in different processes \n",
    "    interact with each other, making it easier to keep track of\n",
    "\n",
    "- pools also hide the passing of data between processes\n",
    "\n",
    "- using a pool looks much like a function call–you pass data into a function, it's executed in another process or processes, and when the work is complete, a value is returned\n",
    "\n",
    "- under the hood, a lot of work is being done to support this–objects in one process are being pickled (serialized) and passed into a pipe, then another process retrieves data from the pipe and unpickles it. \n",
    "\n",
    "    Work is done in the subprocess and a result is produced. The result is pickled and passed into a pipe. Eventually, the original process unpickles it and returns it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Prime multiprocessing\n",
    "--> Head to `multi_pool.py` in PROJECTS folder to try it out \n",
    "- Will not work in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import os\n",
    "from multiprocessing.pool import Pool\n",
    "\n",
    "def prime_factor(value, level=0):\n",
    "    factors = []\n",
    "    if level:\n",
    "        print('    ' * level, 'prime_factor(', value, ', ', level, ') ', os.getpid(), sep='')\n",
    "    for divisor in range(2, value - 1):\n",
    "        quotient, remainder = divmod(value, divisor)\n",
    "        if not remainder:\n",
    "            factors.extend(prime_factor(divisor, level + 1))\n",
    "            factors.extend(prime_factor(quotient, level + 1))\n",
    "            break\n",
    "    else:\n",
    "        factors = [value]\n",
    "    return factors\n",
    "\n",
    "if __name__ == '__main__': # distiguishes between running and importing\n",
    "    pool = Pool()\n",
    "\n",
    "    to_factor = [\n",
    "        random.randint(40_000_000, 80_000_000) \n",
    "                for _ in range(64)\n",
    "    ]\n",
    "    print(to_factor)\n",
    "    results = pool.map(prime_factor, to_factor)\n",
    "    for value, factors in zip(to_factor, results):\n",
    "        print(\"The factors of {} are {}\".format(value, factors))\n",
    "    #print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## another example...\n",
    "we'll need to install `pip install futures` here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Go to get_news.py under PROJECTS\n",
    "\n",
    "### Maybe have pythontutor.com  handy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file download managers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    " \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import as_completed\n",
    " \n",
    "def downloader(url):\n",
    "    \"\"\"\n",
    "    Downloads the specified URL and saves it to disk\n",
    "    \"\"\"\n",
    "    req = urllib.request.urlopen(url)\n",
    "    filename = os.path.basename(url)\n",
    "    ext = os.path.splitext(url)[1]\n",
    "    if not ext:\n",
    "        raise RuntimeError('URL does not contain an extension')\n",
    " \n",
    "    with open(filename, 'wb') as file_handle:\n",
    "        while True:\n",
    "            chunk = req.read(1024)\n",
    "            if not chunk:\n",
    "                break\n",
    "            file_handle.write(chunk)\n",
    "    msg = 'Finished downloading {filename}'.format(filename=filename)\n",
    "    return msg\n",
    " \n",
    "def main(urls):\n",
    "    \"\"\"\n",
    "    Create a thread pool and download specified urls\n",
    "    \"\"\"\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = [executor.submit(downloader, url) for url in urls]\n",
    "        for future in as_completed(futures):\n",
    "            print('sik', future.result())\n",
    "\n",
    "urls = [\"https://www.irs.gov/pub/irs-pdf/f1040.pdf\",\n",
    "        \"https://www.irs.gov/pub/irs-pdf/f1040a.pdf\",\n",
    "        \"https://www.irs.gov/pub/irs-pdf/f1040ez.pdf\",\n",
    "        \"https://www.irs.gov/pub/irs-pdf/f1040es.pdf\",\n",
    "        \"https://www.irs.gov/pub/irs-pdf/f1040sb.pdf\"]\n",
    "if __name__ == '__main__':\n",
    "    main(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous Programming with `asyncio`\n",
    "\n",
    "Asynchronous programming allows for concurrent execution of tasks without the need for explicit threading or process management. \n",
    "\n",
    "Python's `asyncio` module provides a framework for writing **asynchronous code using coroutines and event loops**. \n",
    "\n",
    "Asyncio - best modern version of threading in python\n",
    "\n",
    "Threading - multiple worker threads, but can be cumbersome and can bloat code\n",
    "\n",
    "Processing - Concurrency → extra processes\n",
    "\n",
    "Here's an example that demonstrates the use of `asyncio` -> async_news.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[0;32m---> 19\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def fetch_data(url):\n",
    "    print(f\"Fetching data from {url}\")\n",
    "    await asyncio.sleep(2)  # Simulating network delay\n",
    "    return f\"Data from {url}\"\n",
    "\n",
    "async def main():\n",
    "    urls = [\"https://example.com\", \"https://example.org\", \"https://example.net\"]\n",
    "    tasks = []\n",
    "    for url in urls:\n",
    "        task = asyncio.create_task(fetch_data(url))\n",
    "        tasks.append(task)\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation for above code:\n",
    "\n",
    "- The `fetch_data` function is defined as an asynchronous function using the `async def` syntax. It takes a `url` as an argument and simulates fetching data from that URL by sleeping for 2 seconds using `asyncio.sleep()`.\n",
    "\n",
    "- The `main` function is also defined as an asynchronous function. It contains the main logic of the program.\n",
    "\n",
    "- Inside `main`, we define a list of URLs that we want to fetch data from.\n",
    "\n",
    "- We create a list called `tasks` to store the asynchronous tasks.\n",
    "\n",
    "- For each URL, we create an asynchronous task using `asyncio.create_task()`, passing the `fetch_data` coroutine with the URL as an argument. We append each task to the `tasks` list.\n",
    "\n",
    "- We use `asyncio.gather()` to wait for all the tasks to complete and collect their results. The `` operator is used to unpack the `tasks` list and pass each task as a separate argument to `gather()`.\n",
    "\n",
    "- The `await` keyword is used to wait for the tasks to complete and retrieve their results.\n",
    "\n",
    "- Finally, we iterate over the results and print each one.\n",
    "\n",
    "- The `asyncio.run()` function is used to run the asynchronous `main` function and start the event loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful methods of `asyncio`\n",
    "\n",
    "`asyncio.gather()`  - fast and also preserves the order of outputs\n",
    "\n",
    "`asyncio.ascompleted()` - Speedy but does not preserve order of outputs (gets things done as needed) - so depends on the required context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concurrency and Parallelism Exercise: \n",
    "\n",
    "Implement a program that fetches data from multiple URLs concurrently using threads and another using processes. Compare the performance of each approach.\n",
    "\n",
    "Scenario: You are building a web scraper that needs to fetch data from multiple websites simultaneously. Using concurrency and parallelism can significantly speed up the scraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THREADS IMPLEMENTATION\n",
    "import concurrent.futures\n",
    "import requests\n",
    "\n",
    "def fetch_url(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "def fetch_urls_concurrently(urls):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(fetch_url, url) for url in urls]\n",
    "        results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "    return results\n",
    "\n",
    "urls = [...]  # List of URLs to fetch\n",
    "data = fetch_urls_concurrently(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PROCESSES IMPLEMENTATION\n",
    "import concurrent.futures\n",
    "import requests\n",
    "\n",
    "def fetch_url(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "def fetch_urls_parallel(urls):\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(fetch_url, url) for url in urls]\n",
    "        results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "    return results\n",
    "\n",
    "urls = [...]  # List of URLs to fetch\n",
    "data = fetch_urls_parallel(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thread Synchronization and Object Sharing:\n",
    "Exercise: Implement a thread-safe counter class that multiple threads can increment concurrently without causing race conditions.\n",
    "\n",
    "Scenario: You are building a web server that needs to keep track of the number of requests processed. Multiple threads will be accessing and incrementing the counter simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class ThreadSafeCounter:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def increment(self):\n",
    "        with self.lock:\n",
    "            self.count += 1\n",
    "\n",
    "    def get_count(self):\n",
    "        with self.lock:\n",
    "            return self.count\n",
    "\n",
    "counter = ThreadSafeCounter()\n",
    "\n",
    "def worker():\n",
    "    for _ in range(100000):\n",
    "        counter.increment()\n",
    "\n",
    "threads = []\n",
    "for _ in range(5):\n",
    "    thread = threading.Thread(target=worker)\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"Final count:\", counter.get_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading/Writing Files Asynchronously:\n",
    "\n",
    "Exercise: Implement a program that reads multiple large files asynchronously and counts the occurrence of a specific word in each file.\n",
    "\n",
    "Scenario: You are building a log analysis tool that needs to process multiple large log files efficiently to count the occurrence of a specific error keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def count_word_in_file(file_path, word):\n",
    "    async with asyncio.open(file_path, 'r') as file:\n",
    "        content = await file.read()\n",
    "        count = content.lower().count(word.lower())\n",
    "        return count\n",
    "\n",
    "async def main():\n",
    "    file_paths = [...]  # List of file paths\n",
    "    word = \"error\"\n",
    "    tasks = [asyncio.create_task(count_word_in_file(file_path, word)) for file_path in file_paths]\n",
    "    counts = await asyncio.gather(*tasks)\n",
    "\n",
    "    for file_path, count in zip(file_paths, counts):\n",
    "        print(f\"File: {file_path}, Count: {count}\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling REST APIs Asynchronously:\n",
    "\n",
    "Exercise: Implement a program that makes asynchronous requests to a REST API to fetch user data and update a database.\n",
    "\n",
    "Scenario: You are building a user management system that needs to fetch user data from an external API and update a local database asynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import aiosqlite\n",
    "\n",
    "async def fetch_user_data(session, user_id):\n",
    "    url = f\"https://api.example.com/users/{user_id}\"\n",
    "    async with session.get(url) as response:\n",
    "        return await response.json()\n",
    "\n",
    "async def update_user_in_db(db, user_data):\n",
    "    async with db.execute(\"INSERT OR REPLACE INTO users (id, name, email) VALUES (?, ?, ?)\",\n",
    "                          (user_data['id'], user_data['name'], user_data['email'])):\n",
    "        await db.commit()\n",
    "\n",
    "async def main():\n",
    "    async with aiosqlite.connect(\"users.db\") as db:\n",
    "        await db.execute(\"CREATE TABLE IF NOT EXISTS users (id INTEGER PRIMARY KEY, name TEXT, email TEXT)\")\n",
    "\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            user_ids = [...]  # List of user IDs to fetch\n",
    "            fetch_tasks = [asyncio.create_task(fetch_user_data(session, user_id)) for user_id in user_ids]\n",
    "            user_data_list = await asyncio.gather(*fetch_tasks)\n",
    "\n",
    "            update_tasks = [asyncio.create_task(update_user_in_db(db, user_data)) for user_data in user_data_list]\n",
    "            await asyncio.gather(*update_tasks)\n",
    "\n",
    "asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
